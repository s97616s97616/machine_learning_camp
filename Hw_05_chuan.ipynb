{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error as MSE\n",
    "from sklearn.metrics import mean_absolute_error as MAE\n",
    "from sklearn.metrics import mean_absolute_percentage_error as MAPE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解題步驟：\n",
    "\n",
    "1. 讀取 x_train.npy, y_train.npy, x_test.npy, y_test.npy\n",
    "2. 將 training dataset 再切分為 training set, validation set (圖一)\n",
    "3. 先以上課的知識調整出一個不會 over-fitting 太多的決策樹模型\n",
    "4. 以 validation set 作為調整參數的基準，陸續調整其他參數 (請同學測試看看 validation 要佔多少比例，後續的調整會比較客觀)\n",
    "5. 將最終調整結果與一開始的決策樹做比較，誤差是否有降低\n",
    "6. 同學若也懂其他模型的知識也可以試試看一樣的做法比較看看\n",
    "\n",
    "#### 圖一 (Train, Validation and Test)\n",
    "<img src=\"./train_val_test.png\" style=\"zoom:30%;\" />\n",
    "\n",
    "#### 圖二 (是我前後調整的結果)\n",
    "<img src=\"./report.png\" style=\"zoom:30%;\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data\n",
    "X_train = np.load('x_train.npy')\n",
    "x_test = np.load('x_test.npy')\n",
    "Y_train = np.load('y_train.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 請同學先依照上課的知識，調整一個沒有 overfitting 的決策樹，請以 mape 作為參考誤差指標，較容易看出關係"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_size: 0.5\n",
      "Before tuning\n",
      "train: 0.0\n",
      "val: 0.16611151411831768\n",
      "test: 0.1680821741494072\n",
      "----------------------------\n",
      "After tuning\n",
      "train: 0.10095119237548746\n",
      "val: 0.14515996369878895\n",
      "test: 0.15501782844667686\n",
      "變動幅度衡量:  0.6235503073105848\n",
      "============================\n",
      "test_size: 0.4\n",
      "Before tuning\n",
      "train: 0.0\n",
      "val: 0.14433650152954408\n",
      "test: 0.16546807794053275\n",
      "----------------------------\n",
      "After tuning\n",
      "train: 0.10062583670008882\n",
      "val: 0.12938607279881958\n",
      "test: 0.13896177043059474\n",
      "變動幅度衡量:  1.7729463139384847\n",
      "============================\n",
      "test_size: 0.3\n",
      "Before tuning\n",
      "train: 0.0\n",
      "val: 0.15335225500144978\n",
      "test: 0.14719260024809944\n",
      "----------------------------\n",
      "After tuning\n",
      "train: 0.10820634499598887\n",
      "val: 0.1434810950625671\n",
      "test: 0.13753635079227636\n",
      "變動幅度衡量:  0.9782284468704566\n",
      "============================\n",
      "test_size: 0.2\n",
      "Before tuning\n",
      "train: 0.0\n",
      "val: 0.14711411482111325\n",
      "test: 0.1644773269223586\n",
      "----------------------------\n",
      "After tuning\n",
      "train: 0.10835996557581787\n",
      "val: 0.13082307795408604\n",
      "test: 0.1404385860954004\n",
      "變動幅度衡量:  1.475580776298668\n",
      "============================\n",
      "test_size: 0.1\n",
      "Before tuning\n",
      "train: 0.0\n",
      "val: 0.12963223246009942\n",
      "test: 0.15139341170176004\n",
      "----------------------------\n",
      "After tuning\n",
      "train: 0.11069855778264098\n",
      "val: 0.12896159378261218\n",
      "test: 0.13360050555910025\n",
      "變動幅度衡量:  26.53128538504028\n",
      "============================\n",
      "test_size: 0.05\n",
      "Before tuning\n",
      "train: 0.0\n",
      "val: 0.13276199622585438\n",
      "test: 0.15509892974188844\n",
      "----------------------------\n",
      "After tuning\n",
      "train: 0.10963767039189333\n",
      "val: 0.10210040207781297\n",
      "test: 0.13484327729493786\n",
      "變動幅度衡量:  0.6606196778012097\n",
      "============================\n",
      "test_size: 0.01\n",
      "Before tuning\n",
      "train: 0.0\n",
      "val: 0.11288639690751809\n",
      "test: 0.15090328881816042\n",
      "----------------------------\n",
      "After tuning\n",
      "train: 0.1100222397149872\n",
      "val: 0.07885932705602443\n",
      "test: 0.13509793637808468\n",
      "變動幅度衡量:  0.4644934903021617\n",
      "============================\n"
     ]
    }
   ],
   "source": [
    "triallist = [0.5, 0.4, 0.3, 0.2, 0.1, 0.05, 0.01]\n",
    "for num in triallist:\n",
    "    x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=num)\n",
    "    print('test_size:',num)\n",
    "    print('Before tuning')\n",
    "    reg = DecisionTreeRegressor().fit(x_train, y_train)\n",
    "    y_pred_train = reg.predict(x_train)\n",
    "    print('train:', MAPE(y_pred_train, y_train))\n",
    "    y_pred = reg.predict(x_val)\n",
    "    before_val = MAPE(y_pred, y_val)\n",
    "    print('val:', before_val)\n",
    "    y_pred_test = reg.predict(x_test)\n",
    "    before_test = MAPE(y_pred_test, y_test)\n",
    "    print('test:', before_test)\n",
    "    print('----------------------------')\n",
    "    print('After tuning')\n",
    "    reg_tune = DecisionTreeRegressor(max_depth=5, min_samples_split=3, min_samples_leaf=2, max_features=0.8, min_impurity_decrease=0.5, ccp_alpha=1.0, random_state=42).fit(x_train, y_train)\n",
    "    y_pred_train = reg_tune.predict(x_train)\n",
    "    print('train:', MAPE(y_pred_train, y_train))\n",
    "    y_pred = reg_tune.predict(x_val)\n",
    "    tune_val = MAPE(y_pred, y_val)\n",
    "    print('val:', tune_val)\n",
    "    y_pred_test = reg_tune.predict(x_test)\n",
    "    tune_test = MAPE(y_pred_test, y_test)\n",
    "    print('test:', tune_test)\n",
    "    print('變動幅度衡量: ', (before_test-tune_test)/(before_val-tune_val))\n",
    "    print('============================')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#由上面實驗發現當test_size為0.1時，val的變動幅度與test的變動幅度為0.97最為相近，\n",
    "#代表調參時val最能反映test的測試結果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 調整 決策樹參數\n",
    "### 請同學從 criterion 的設定中，判斷這組資料集裡的 outlier 多嗎？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "criterion:MSE 0.16627169158136268\n",
      "criterion:MAE 0.13967992009617888\n"
     ]
    }
   ],
   "source": [
    "#MSE較MAE的MAPE高一些，表示資料內應有離群值，但我也不知道您的outlier要多少才算多~\n",
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.1, random_state=42)\n",
    "reg = DecisionTreeRegressor().fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_val)\n",
    "before_val = MAPE(y_pred, y_val)\n",
    "print('criterion:MSE', before_val)\n",
    "reg = DecisionTreeRegressor(criterion='mae').fit(x_train, y_train)\n",
    "y_pred = reg.predict(x_val)\n",
    "before_val = MAPE(y_pred, y_val)\n",
    "print('criterion:MAE', before_val)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
